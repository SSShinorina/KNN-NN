# -*- coding: utf-8 -*-
"""Copy of Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vVI3u0JKc7hmsdbxjwPsUR2Wz6rNEczI
"""

course_5DV124 = True

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_digits
np.random.seed(42)

mnist = load_digits()
 
X = mnist.data
y = mnist.target
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=123)
print(Xtrain.shape, ytrain.shape)
print(Xtest.shape, ytest.shape)



# import sklearn.datasets

# data = sklearn.datasets.fetch_openml("mnist_784")

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

fig = plt.figure(figsize=(12, 7.75))
fig.subplots_adjust(top=0.995,
                    bottom=0.115,
                    left=0.005,
                    right=0.995,
                    wspace=0.15,
                    hspace=0.005)

plot_array = (2, 4)
ax = [[None] * plot_array[1]] * plot_array[0]
it = 0
for i in range(plot_array[0]):
    for j in range(plot_array[1]):
        ax[i][j] = plt.subplot2grid((2, 4), (i, j), rowspan=1, colspan=1)
        # ax[i][j].imshow(Xtrain[it, :].reshape((8, 8)))
        ax[i][j].imshow(Xtrain[it, :].reshape((8,8)))
        ax[i][j].set_title(f"Label: {ytrain[it]}", fontsize=24)
        it += 1

import sklearn.preprocessing

print(f"Before preprocessing, test data       : "
      f"min = {np.min(Xtrain):.1f}, "
      f"max = {np.max(Xtrain):.1f}, "
      f"mean = {np.mean(Xtrain):.1f}, "
      f"std = {np.std(Xtrain):.1f}")
# print(f"Before preprocessing, validation data : "
#       f"min = {np.min(Xval):.1f}, "
#       f"max = {np.max(Xval):.1f}, "
#       f"mean = {np.mean(Xval):.1f}, "
#       f"std = {np.std(Xval):.1f}")
print(f"Before preprocessing, test data       : "
      f"min = {np.min(Xtest):.1f}, "
      f"max = {np.max(Xtest):.1f}, "
      f"mean = {np.mean(Xtest):.1f}, "
      f"std = {np.std(Xtest):.1f}")

scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))
scaler.fit(Xtrain)  # Every statistic we compute is found on the training data!

Xtrain = scaler.transform(Xtrain)
# Xval = scaler.transform(Xval)
# TODO: If you do cross-validation, you must redo this on the training data in
#       each cross-validation loop, and then transform the validation data as
#       well!
Xtest = scaler.transform(Xtest)

print(f"After preprocessing, test data        : "
      f"min = {np.min(Xtrain):.1f}, "
      f"max = {np.max(Xtrain):.1f}, "
      f"mean = {np.mean(Xtrain):.1f}, "
      f"std = {np.std(Xtrain):.1f}")
# print(f"After preprocessing, validation data  : "
#       f"min = {np.min(Xval):.1f}, "
#       f"max = {np.max(Xval):.1f}, "
#       f"mean = {np.mean(Xval):.1f}, "
#       f"std = {np.std(Xval):.1f}")
print(f"After preprocessing, test data        : "
      f"min = {np.min(Xtest):.1f}, "
      f"max = {np.max(Xtest):.1f}, "
      f"mean = {np.mean(Xtest):.1f}, "
      f"std = {np.std(Xtest):.1f}")

# TODO: Try to apply other preprocessing, e.g. the
#       sklearn.preprocessing.StandardScaler(), and see if the results improve.

"""KNN"""

# Take help from https://medium.com/analytics-vidhya/a-beginners-guide-to-knn-and-mnist-handwritten-digits-recognition-using-knn-from-scratch-df6fb982748a
import sklearn.neighbors
import math
import operator 
from operator import itemgetter

def euc_dist(x1, x2):
  diff = abs(x1-x2)
  diff = sum(pow(diff,2))
  return math.sqrt(diff)
def get_Accuracy(ytrue, ypred):
    n_correct = 0
    for i in range(len(ytrue)):
        if ytrue[i] == ypred[i]:
            n_correct += 1
            acc = n_correct/len(ytrue)
    return acc*100

if course_5DV124:
    # TODO: Create your own nearest neighbour classifier:
    class KNN:
      def __init__(self, K=3):
        self.K = K
      def fit(self, Xtrain, ytrain):
        self.Xtrain = Xtrain
        self.ytrain = ytrain
      def predict(self, Xtest):
        predictions = [] 
        for i in range(len(Xtest)):
          dist = np.array([euc_dist(Xtest[i], x_t) for x_t in   
          self.Xtrain])
          dist_sorted = dist.argsort()[:self.K]
          neigh_count = {}
          for idx in dist_sorted:
            if self.ytrain[idx] in neigh_count:
                neigh_count[self.ytrain[idx]] += 1
            else:
                neigh_count[self.ytrain[idx]] = 1
          sorted_neigh_count = sorted(neigh_count.items(),key=operator.itemgetter(1), reverse=True)
          predictions.append(sorted_neigh_count[0][0]) 
        return predictions

kVals = np.arange(3,20,2)
accuracies = []
for k in kVals:
  model = KNN(K = k)
  model.fit(Xtrain[:50000,:], ytrain[:50000])
  pred = model.predict(Xtest)
  acc = get_Accuracy(ytest, pred)
  print(f"Number of neighbours: k={k}, validation accuracy: {acc}")
accuracies.append(acc)
print("Grid search done!")

fig = plt.figure(figsize=(8, 5))
fig.subplots_adjust(top=0.995,
                    bottom=0.115,
                    left=0.005,
                    right=0.995,
                    wspace=0.15,
                    hspace=0.005)

ax0 = plt.subplot2grid((1, 1), (0, 0), rowspan=1, colspan=1)
ax0.plot(range(1, len(accuracies) + 1), accuracies)
ax0.set_title("Result of $k$-NN Grid-Search", fontsize=24)
ax0.set_xlabel("Number of Neighbours, $k$", fontsize=16)
ax0.set_ylabel("Validation Accuracy", fontsize=16)

k_best = np.argmax(accuracies) + 1  # Note that k=1 is at index 0.
print(f"The best value was {accuracies[k_best - 1]}, found using k={k_best}.")

model_knn = KNN(K=k_best)
model_knn.fit(Xtrain[:50000, :], ytrain[:50000])
err = get_Accuracy(ytest, pred)
print(f"Final validation accuracy: {err}")

"""NN"""

# take help from https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?fbclid=IwAR2fZuoU38f0RfidvpPzG1qNuEDG534lHvz01sopiOg2_Vex5IuGqfw0vuY#
import sklearn.neural_network
from sklearn import svm, datasets
from sklearn.model_selection import GridSearchCV
from keras.wrappers.scikit_learn import KerasClassifier
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import np_utils
 

parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}
svc = svm.SVC()
clf = GridSearchCV(svc, parameters)


# Set the maximum and minimum number of neurons for each layer.
hidden_layer_sizes_min = [400, 300]
hidden_layer_sizes_max = [500, 400]

errs_val = {}
num_neurons_1 = 250
num_neurons_2 = 30
# num_neurons_3 = 100
hidden_layer_sizes = (num_neurons_1, num_neurons_2)  # , num_neurons_3)
model = sklearn.neural_network.MLPClassifier(
    hidden_layer_sizes=hidden_layer_sizes,
    activation='relu',
    alpha=0.0001,
    batch_size='auto',
    learning_rate_init=0.001,
    max_iter=200,
)
# TODO: The computations may take a long time here as well. Play with
#       different amounts of data to see what's feasible on your
#       computer. Get it to work on a small amount of data first, and
#       then run for a longer time with more data. More data here will
#       improve the results. Using all data may take a long time, but
#       will give good results.
model.fit(Xtrain[:50000, :], ytrain[:50000])
err = model.score(Xtest[:10000, :], ytest[:10000])
print(f"Hidden layer sizes: {hidden_layer_sizes}, "
        f"validation accuracy: {err*100}")

clf.fit(Xtrain[:50000, :], ytrain[:50000])
grid_err = clf.score(Xtest[:10000, :], ytest[:10000])
print(f"sizes: {parameters}, "
        f"grid search accuracy: {grid_err*100}")
errs_val[hidden_layer_sizes] = err

print("Grid search done!")

# Train the final model using the best layer sizes

hidden_layer_sizes_best = max(errs_val, key=errs_val.get, default='')
print(f"The best value was {errs_val[hidden_layer_sizes_best]}, "
      f"found using layer sizes: {hidden_layer_sizes_best}.")

model_ann = sklearn.neural_network.MLPClassifier(
    hidden_layer_sizes=hidden_layer_sizes_best,
    alpha=0.0001,
    batch_size='auto',
    learning_rate_init=0.001,
    max_iter=300,
)

model_ann.fit(Xtrain[:50000, :], ytrain[:50000])
err = model_ann.score(Xtest[:10000, :], ytest[:10000])
err = round(err*100)

clf.fit(Xtrain[:50000, :], ytrain[:50000])
grid_err = clf.score(Xtest[:10000, :], ytest[:10000])
grid_err = round(grid_err*100)
 

print(f"Final validation accuracy: {err}")
print(f"Final validation accuracy using grid search: {grid_err}")

# Evaluate the final model on all the data sets, including the test data. We
# only evaluate the test data once, and as the last thing we do. If you train
# another model after this, based on the performance on the test data, then your
# test data is effectively a validation dataset, and you no longer have a test
# dataset. (Or, if you keep your test data set, then your results are biased and
# by that unreliable.)
# print(f"k-NN model training data accuracy  : {model_knn.score(Xtrain, ytrain)}")
# print(f"k-NN model validation data accuracy: {model_knn.score(Xval, yval)}")
if False:  # Change this to True as the very last thing you do!
    print(f"k-NN model test data accuracy      : "
          f"{model_knn.score(Xtest, ytest)}")

print(f"ANN model training data accuracy   : {model_ann.score(Xtrain, ytrain)}")
print(f"ANN model validation data accuracy : {model_ann.score(Xtest, ytest)}")

print(f"ANN model training data accuracy using grid search   : {clf.score(Xtrain, ytrain)}")
print(f"ANN model validation data accuracy using grid search : {clf.score(Xtest, ytest)}")
if False:  # Change this to True as the very last thing you do!
    print(f"ANN model test data accuracy       : "
          f"{model_ann.score(Xtest, ytest)}")